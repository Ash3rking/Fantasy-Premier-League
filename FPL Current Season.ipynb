{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96f222ad-c493-4a2b-badb-b564dc0834bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session (Databricks automatically provides this)\n",
    "spark = SparkSession.builder.appName(\"FPL_Current_Season_Gameweek_History\").getOrCreate()\n",
    "\n",
    "# Base API URL\n",
    "BASE_URL = \"https://fantasy.premierleague.com/api/\"\n",
    "\n",
    "# Fetch all player metadata (names, teams, positions)\n",
    "def get_all_players():\n",
    "    \"\"\"Fetches all players from the FPL API.\"\"\"\n",
    "    response = requests.get(BASE_URL + \"bootstrap-static/\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df_players = pd.DataFrame(data[\"elements\"])\n",
    "        df_teams = pd.DataFrame(data[\"teams\"])  # Fetch team info\n",
    "        \n",
    "        # Map team_id to team name\n",
    "        team_map = df_teams.set_index(\"id\")[\"name\"].to_dict()\n",
    "        df_players[\"team_name\"] = df_players[\"team\"].map(team_map)\n",
    "        \n",
    "        # Map element_type to position names\n",
    "        position_map = {1: \"Goalkeeper\", 2: \"Defender\", 3: \"Midfielder\", 4: \"Forward\"}\n",
    "        df_players[\"position\"] = df_players[\"element_type\"].map(position_map)\n",
    "        \n",
    "        return df_players\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Failed to fetch player data!\")\n",
    "        return None\n",
    "\n",
    "# Fetch per-gameweek stats for a given player\n",
    "def get_gameweek_history(player_id):\n",
    "    \"\"\"Fetches all per-gameweek stats for a given player.\"\"\"\n",
    "    try:\n",
    "        url = f\"{BASE_URL}element-summary/{player_id}/\"\n",
    "        r = requests.get(url).json()\n",
    "        \n",
    "        # Extract gameweek history\n",
    "        df = pd.json_normalize(r[\"history\"])\n",
    "        df[\"player_id\"] = player_id  # Add player ID for merging\n",
    "        \n",
    "        return df\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch gameweek history for player {player_id}\")\n",
    "        return None\n",
    "\n",
    "# Fetch all players\n",
    "df_players = get_all_players()\n",
    "\n",
    "if df_players is not None:\n",
    "    player_ids = df_players[\"id\"].tolist()  # Extract all player IDs\n",
    "\n",
    "    # Fetch per-gameweek history for all players\n",
    "    all_histories = []\n",
    "    for player_id in player_ids:\n",
    "        print(f\"üì° Fetching gameweek history for player {player_id}...\")\n",
    "        df_history = get_gameweek_history(player_id)\n",
    "        if df_history is not None:\n",
    "            all_histories.append(df_history)\n",
    "\n",
    "    # Merge all player histories into one DataFrame\n",
    "    df_gameweeks = pd.concat(all_histories, ignore_index=True)\n",
    "\n",
    "    # Select ALL available columns\n",
    "    df_gameweeks = df_gameweeks[[\n",
    "        \"player_id\", \"round\", \"minutes\", \"goals_scored\", \"assists\", \"clean_sheets\", \n",
    "        \"goals_conceded\", \"own_goals\", \"penalties_saved\", \"penalties_missed\", \n",
    "        \"yellow_cards\", \"red_cards\", \"saves\", \"bonus\", \"bps\", \n",
    "        \"expected_goals\", \"expected_assists\", \"expected_goal_involvements\", \"expected_goals_conceded\",\n",
    "        \"total_points\", \"influence\", \"creativity\", \"threat\", \"ict_index\", \n",
    "        \"transfers_in\", \"transfers_out\", \"selected\", \"value\"\n",
    "    ]]\n",
    "\n",
    "    # Merge with player metadata (names, teams, positions)\n",
    "    df_final = df_gameweeks.merge(\n",
    "        df_players[[\"id\", \"web_name\", \"team_name\", \"position\"]], \n",
    "        left_on=\"player_id\", right_on=\"id\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Drop redundant columns\n",
    "    df_final.drop(columns=[\"player_id\", \"id\"], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df_final = df_final[[\n",
    "        \"web_name\", \"team_name\", \"position\", \"round\",\n",
    "        \"minutes\", \"goals_scored\", \"assists\", \"clean_sheets\", \"goals_conceded\",\n",
    "        \"own_goals\", \"penalties_saved\", \"penalties_missed\", \"yellow_cards\", \"red_cards\",\n",
    "        \"saves\", \"bonus\", \"bps\", \"expected_goals\", \"expected_assists\", \"expected_goal_involvements\",\n",
    "        \"expected_goals_conceded\", \"total_points\", \"influence\", \"creativity\", \"threat\", \"ict_index\",\n",
    "        \"transfers_in\", \"transfers_out\", \"selected\", \"value\"\n",
    "    ]]\n",
    "\n",
    "    # Convert to Spark DataFrame\n",
    "    df_spark = spark.createDataFrame(df_final)\n",
    "\n",
    "    # Save to Databricks Table with schema evolution enabled\n",
    "    df_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"fpl.season_2024_25.gameweek_history\")\n",
    "\n",
    "    print(\"‚úÖ Current Season Gameweek History Table Successfully Created in Databricks!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FPL Current Season",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
